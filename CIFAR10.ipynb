{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i180423_B_Ass3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "X9t8nG05YxZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K0gMMY2I3baf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the cifar10 dataset from keras dataset"
      ],
      "metadata": {
        "id": "o2FWGBUWY1vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "5b1tP2wv3_oe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Normalization and pre-processing"
      ],
      "metadata": {
        "id": "f8oRohTlY7Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the data to get data in range 0-1\n",
        "X_train = X_train.astype('float32') \n",
        "X_test = X_test.astype('float32') \n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0\n",
        "#Converting to categorical \n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "wAKpwdWJ4CmM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the training set into training and validation set"
      ],
      "metadata": {
        "id": "VMrWEhVrY_Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, yy_train, yy_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "AZlL5d3qPjgn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network model layers"
      ],
      "metadata": {
        "id": "aiLBCYY2ZEMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "#Convolutional 2D Layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "#Batch Normalization Layer\n",
        "model.add(BatchNormalization())\n",
        "#Max Pooling layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "#Dropout layer with a dropout rate of 0.25\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Flatten Layer\n",
        "model.add(Flatten())\n",
        "#Fully Connected Layer with relu activation function\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "#Output layer with softmax activation function\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "ws9i5elk4KcS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of our Model"
      ],
      "metadata": {
        "id": "3PIK8d8Qa4MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBjN7i9-a3yk",
        "outputId": "8a80152d-be8a-4c24-fd70-065be734e459"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357,706\n",
            "Trainable params: 357,258\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model using categorical cross entropy loss function and adam optimizer.\n",
        "Training the model for 20 epochs using a batch size of 32, also using our validation set as our validation dataset for model training "
      ],
      "metadata": {
        "id": "n2pB0A4qZJab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "met = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics= met)\n",
        "model.fit(x_train, yy_train, epochs=20 ,validation_data=(x_val, yy_val),batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnW3GS8M4gkN",
        "outputId": "34386326-6c2a-43d9-aa25-34d03e4f0a34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 12s 7ms/step - loss: 1.6309 - accuracy: 0.4158 - precision: 0.6091 - recall: 0.2026 - val_loss: 1.4144 - val_accuracy: 0.4935 - val_precision: 0.6346 - val_recall: 0.3503\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2845 - accuracy: 0.5422 - precision: 0.7095 - recall: 0.3726 - val_loss: 1.5361 - val_accuracy: 0.5221 - val_precision: 0.6143 - val_recall: 0.4272\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1297 - accuracy: 0.5990 - precision: 0.7456 - recall: 0.4559 - val_loss: 1.1534 - val_accuracy: 0.6038 - val_precision: 0.7171 - val_recall: 0.5074\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 1.0334 - accuracy: 0.6381 - precision: 0.7678 - recall: 0.5090 - val_loss: 1.3965 - val_accuracy: 0.5584 - val_precision: 0.6450 - val_recall: 0.4750\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.9587 - accuracy: 0.6634 - precision: 0.7837 - recall: 0.5492 - val_loss: 0.9590 - val_accuracy: 0.6618 - val_precision: 0.7633 - val_recall: 0.5563\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9021 - accuracy: 0.6835 - precision: 0.7945 - recall: 0.5770 - val_loss: 0.9633 - val_accuracy: 0.6750 - val_precision: 0.7658 - val_recall: 0.6056\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8557 - accuracy: 0.7021 - precision: 0.8053 - recall: 0.6036 - val_loss: 0.8022 - val_accuracy: 0.7284 - val_precision: 0.8151 - val_recall: 0.6360\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8129 - accuracy: 0.7180 - precision: 0.8145 - recall: 0.6243 - val_loss: 0.8943 - val_accuracy: 0.6915 - val_precision: 0.7919 - val_recall: 0.6008\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7764 - accuracy: 0.7311 - precision: 0.8222 - recall: 0.6460 - val_loss: 0.8051 - val_accuracy: 0.7197 - val_precision: 0.8126 - val_recall: 0.6338\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7531 - accuracy: 0.7382 - precision: 0.8264 - recall: 0.6533 - val_loss: 0.9157 - val_accuracy: 0.6937 - val_precision: 0.7604 - val_recall: 0.6372\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7252 - accuracy: 0.7488 - precision: 0.8317 - recall: 0.6680 - val_loss: 0.7722 - val_accuracy: 0.7444 - val_precision: 0.8127 - val_recall: 0.6855\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7003 - accuracy: 0.7561 - precision: 0.8359 - recall: 0.6799 - val_loss: 0.7534 - val_accuracy: 0.7483 - val_precision: 0.8135 - val_recall: 0.6933\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6769 - accuracy: 0.7647 - precision: 0.8413 - recall: 0.6932 - val_loss: 0.7693 - val_accuracy: 0.7481 - val_precision: 0.8099 - val_recall: 0.6970\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6632 - accuracy: 0.7694 - precision: 0.8441 - recall: 0.6999 - val_loss: 0.8722 - val_accuracy: 0.7118 - val_precision: 0.7834 - val_recall: 0.6559\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6436 - accuracy: 0.7770 - precision: 0.8492 - recall: 0.7116 - val_loss: 0.7566 - val_accuracy: 0.7508 - val_precision: 0.8123 - val_recall: 0.7018\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6201 - accuracy: 0.7847 - precision: 0.8530 - recall: 0.7225 - val_loss: 0.8383 - val_accuracy: 0.7287 - val_precision: 0.7892 - val_recall: 0.6774\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6045 - accuracy: 0.7887 - precision: 0.8542 - recall: 0.7273 - val_loss: 0.7498 - val_accuracy: 0.7624 - val_precision: 0.8187 - val_recall: 0.7166\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5987 - accuracy: 0.7921 - precision: 0.8574 - recall: 0.7318 - val_loss: 0.7013 - val_accuracy: 0.7745 - val_precision: 0.8282 - val_recall: 0.7298\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5684 - accuracy: 0.8032 - precision: 0.8634 - recall: 0.7476 - val_loss: 0.8317 - val_accuracy: 0.7353 - val_precision: 0.8016 - val_recall: 0.6899\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5572 - accuracy: 0.8051 - precision: 0.8631 - recall: 0.7507 - val_loss: 0.6341 - val_accuracy: 0.7949 - val_precision: 0.8404 - val_recall: 0.7567\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc430063810>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating model performance on our test set"
      ],
      "metadata": {
        "id": "WuaWb4izZp7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: \",evaluate[1])\n",
        "print(\"Precision: \", evaluate[2])\n",
        "print(\"Recall: \", evaluate[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVj21yyQLGxV",
        "outputId": "d5ff55a2-29c2-44b4-d6a8-f001e947bd5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6364 - accuracy: 0.7938 - precision: 0.8417 - recall: 0.7562\n",
            "Accuracy:  0.7937999963760376\n",
            "Precision:  0.8417186141014099\n",
            "Recall:  0.7562000155448914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping our testing and training features as we need a 2d matrix for our KNN and Naive Bayes ML models"
      ],
      "metadata": {
        "id": "y7433GtdZuCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))"
      ],
      "metadata": {
        "id": "U19Vl3mXR0Of"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and evaluating KNN classifier performance on cifar10"
      ],
      "metadata": {
        "id": "RrjUc0HfZ70L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "predict = knn.predict(X_test)\n",
        "print(\"KNN classifier\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predict)}\")\n",
        "print(\"Precision: \", precision_score(y_test, predict,average='weighted'))\n",
        "print(\"Recall: \", recall_score(y_test, predict,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH85Af88KOok",
        "outputId": "5cf11100-fde6-42e6-d383-f7d2ae1f5320"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN classifier\n",
            "Accuracy: 0.2453\n",
            "Precision:  0.5645490388999024\n",
            "Recall:  0.2453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a 2d array so we'll reshape to a 1d array as in input to our Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "MEBAV7nZaGO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yy_train = y_train[:, 0]\n",
        "yy_test = y_test[:, 0]"
      ],
      "metadata": {
        "id": "guCWqrLyUk8n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and evaluating Naive Bayes classifier performance on cifar10"
      ],
      "metadata": {
        "id": "vd7Fv3AQaRXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, yy_train)\n",
        "predict = gnb.predict(X_test)\n",
        "print(\"KNN classifier\")\n",
        "print(f\"Accuracy: {accuracy_score(yy_test, predict)}\")\n",
        "print(\"Precision: \", precision_score(yy_test, predict,average='weighted'))\n",
        "print(\"Recall: \", recall_score(yy_test, predict,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njBeMP-JSat3",
        "outputId": "a6a40622-0f28-433e-a419-2aed35f1f713"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN classifier\n",
            "Accuracy: 0.6967\n",
            "Precision:  0.8814086553491397\n",
            "Recall:  0.6967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparitive Analysis**\n",
        "\n",
        "*Convolutional Neural Network*\n",
        "\n",
        "CNN model takes longer time in training however once trained it provides the best test time perdictions. We have trained our CNN model for 20 epochs with a 32 batch size of input data. Our model has 3 each of our Conv2D, Batch Normalization and Max2D Pooling Layers. Additionally we have used a dropout of 0.25 so that at 75% of neurons only contribute at one time giving a chance to all the neurons to participate. We have used relu activation function at our fully connected layer and a softmax activation function at our output layer which predicts the labels for 10 classes of cifar10 dataset. Our model achieves a test time accuracy of 79.3% followed by a recall and precision of 0.75 and 0.84 respectively.\n",
        "\n",
        "*K Nearest Neighbor*\n",
        "\n",
        "We have trained our KNN model for 5 neighbors on cifar10 training dataset. We have further evaluated our models performance for the 10,000 test dataset items. Our model does'nt produce satisfactory results. Model produces an accuracy, precision and recall of 24.5%,0.56,0.24 respectively.\n",
        "\n",
        "*Naive Bayes Classifier*\n",
        "\n",
        "Our Naive Bayes Classifier produces better results than KNN however not as good as our CNN model. Our model achieves a test time accuracy of 69.6% followed by precision and recall of 0.88,0.69 respectively.\n",
        "\n",
        "\n",
        "**Comparison**\n",
        "\n",
        "In terms of time complexity, CNN took the longest time at training followed by KNN, however Naive Bayes took the least time. In terms of performance as we can see from the evaluation metrics CNN performed the best in classification of cifar-10 dataset. All these models can be used for mutliclass classification but as we can see CNN is a neural network where at each layers features and weights are learned it produces better results as compared to others"
      ],
      "metadata": {
        "id": "FnZA0R_iaXOG"
      }
    }
  ]
}